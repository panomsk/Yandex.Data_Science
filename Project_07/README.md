
# Отток клиентов
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

**Описание данных**   
**Признаки**  
•	RowNumber — индекс строки в данных  
•	CustomerId — уникальный идентификатор клиента  
•	Surname — фамилия  
•	CreditScore — кредитный рейтинг  
•	Geography — страна проживания  
•	Gender — пол  
•	Age — возраст  
•	Tenure — сколько лет человек является клиентом банка  
•	Balance — баланс на счёте  
•	NumOfProducts — количество продуктов банка, используемых клиентом  
•	HasCrCard — наличие кредитной карты  
•	IsActiveMember — активность клиента  
•	EstimatedSalary — предполагаемая зарплата  
**Целевой признак**  
•	Exited — факт ухода клиент  

## Общий вывод по проекту
**При выполнении проекта:**

На этапе подготовки данных
- Данные из файла Churn.csv загружены в dataframe с именем df.      
- Набор данных состоит из 14 колонок и 10000 записей (объектов).      
- Дубликаты в исходных данных отсутствуют.  
- Признаки RowNumber, CustomerId и Surname удалены, т.к. не будут использоваться для классификации. 
- Объекты по целевому признаку в исходной выборке разделены в соотношении 1 к 4, т.е. наблюдается перекос в исходных данных.  
- Проведено прямое кодирование категориальных переменных.   
- Исходная выборка разбита на обучающую, валидационную и тестовую выборки в пропорции 60-20-20.
- Проведено масштабирование количественных признаков.

На этапе исследования задачи:  
- Исследованы три модели машинного обучения для классификации: логистическая регрессия, дерево решений и случайный лес. Проведена настройка гиперпараметров моделей для подбора параметров с максимальным значением f1_score, auc_score на валидационной выборке.    
- Наилучшие результаты f1_score = 0.6, roc_auc_score = 0.84 получены для модели RandomForestClassifier со следующими параметрами:
       RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=13, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10,
                       n_jobs=None, oob_score=False, random_state=12345,
                       verbose=0, warm_start=False)
                       
- Предсказуемо, результаты на тестовых данных оказались хуже чем на валидационных и нужного значения F1_score мы не достигли. Будем бороться с дисбаллансом классов.

На этапе борьбы с дисбаллансом:
Проверены 3 метода борьбы с дисбаллансом классов:  
- Использование при обучении параметра (class_weight='balanced')
- Upsampling
- Downsampling  
- Исследованы три модели машинного обучения для классификации: логистическая регрессия, дерево решений и случайный лес. Проведена настройка гиперпараметров моделей для подбора параметров с максимальным значением f1_score, auc_score на валидационной выборке.    
- Выбраны две лучшие модели для проверки на тестовой выборке. Лучшие показатели для f1_score и roc_auc получены для разных гиперпараметров моделей, но поскольку целевой показатель в заданиее f1_score, то при выборе моделей для тестирования будем ориентироваться впервую очередь на него.

На этапе тестирования модели:  
- Наилучшие результаты на тестовой выборке (f1_score = 0.603, auc_score = 0.852) получены для модели RandomForestClassifier со следующими параметрами:  
       RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=4,
                       min_weight_fraction_leaf=0.0, n_estimators=40,
                       n_jobs=None, oob_score=False, random_state=12345,
                       verbose=0, warm_start=False)
                       
Наиболее важными факторами оказались возраст, количество продуктов, баланс, кредитный рейтинг, зарплата. 
    По гистограммам можно было предположить влияние возраста и количества продуктов, по коэффициенту корреляции можно было выделить возраст и баланс. Но значимость остальных факторов не очевидна на этапе предварительного анализа данных.